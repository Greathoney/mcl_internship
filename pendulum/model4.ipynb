{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.replay_memory = []\n",
    "\n",
    "        self.dense1 = Dense(48, activation=\"relu\", input_dim=state_size)\n",
    "        self.dense2 = Dense(48, activation=\"relu\")\n",
    "        self.dense2 = Dense(48, activation=\"relu\")\n",
    "        self.dense3 = Dense(action_size, activation=\"softmax\")\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.optimizer_side = tf.keras.optimizers.Adam(learning_rate=0.0004)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory.append((state, action, reward, next_state, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(model: DQN):\n",
    "    # 리플레이 버퍼 크기가 작으면 업데이트하지 않음\n",
    "    if len(model.replay_memory) < 1000:\n",
    "        return\n",
    "    \n",
    "    # 너무 많으면 리플레이 버퍼 pop\n",
    "    if len(model.replay_memory) > 10000:\n",
    "        model.replay_memory.pop(0)\n",
    "\n",
    "    # 메모리에서 랜덤 샘플링\n",
    "    sample_size = 64\n",
    "    samples = random.sample(model.replay_memory, sample_size)\n",
    "\n",
    "    # 분할\n",
    "    states, actions, rewards, next_states, dones = zip(*samples)\n",
    "    # states, actions, rewards, next_states, dones = zip(*model.replay_memory)\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    states = np.array(states)\n",
    "    actions = np.array(actions)\n",
    "    rewards = np.array(rewards)\n",
    "    next_states = np.array(next_states)\n",
    "    dones = np.array(dones)\n",
    "\n",
    "    # 모델 예측과 타겟 값 계산\n",
    "    targets = model.call(states).numpy()\n",
    "    next_q_values = model.call(next_states).numpy()\n",
    "\n",
    "    targets[np.arange(sample_size), actions] = rewards + 0.95 * np.max(next_q_values, axis=1) * (1 - dones)\n",
    "\n",
    "    # 모델 업데이트\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_values = model.call(states)\n",
    "        loss = tf.keras.losses.mean_squared_error(targets, q_values)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "\n",
    "    left_index = np.where(actions != 0)\n",
    "    targets_left = model.call(states).numpy()\n",
    "    next_q_values_left = model.call(next_states).numpy()[left_index]\n",
    "\n",
    "    targets_left[left_index[0], actions[left_index]] = rewards[left_index] + 0.95 * np.max(next_q_values_left, axis=1) * (1 - dones[left_index])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_values = model.call(states)\n",
    "        loss = tf.keras.losses.mean_squared_error(targets_left, q_values)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer_side.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "\n",
    "    right_index = np.where(actions != 8)\n",
    "    targets_right = model.call(states).numpy()\n",
    "    next_q_values_right = model.call(next_states).numpy()[right_index]\n",
    "\n",
    "    targets_right[right_index[0], actions[right_index]] = rewards[right_index] + 0.95 * np.max(next_q_values_right, axis=1) * (1 - dones[right_index])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_values = model.call(states)\n",
    "        loss = tf.keras.losses.mean_squared_error(targets_right, q_values)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer_side.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Steps: 300, Score: -8.13066480673677\n",
      "Episode: 1, Steps: 300, Score: -6.041336974261138\n",
      "Episode: 2, Steps: 300, Score: -6.239332050959648\n",
      "Episode: 3, Steps: 300, Score: -8.056297408954602\n",
      "Episode: 4, Steps: 300, Score: -5.779184215683671\n",
      "Episode: 5, Steps: 300, Score: -7.9023308182630885\n",
      "Episode: 6, Steps: 300, Score: -6.125682195612535\n",
      "Episode: 7, Steps: 300, Score: -7.883861765048579\n",
      "Episode: 8, Steps: 300, Score: -6.531899033140856\n",
      "Episode: 9, Steps: 300, Score: -6.338818527358223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9776\\2505426590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# 모델 업데이트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9776\\2743324410.py\u001b[0m in \u001b[0;36mupdate_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_side\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36maggregate_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1103\u001b[0m           \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \"\"\"\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_reduce_sum_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     def apply_gradients(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mall_reduce_sum_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             reduced = tf.distribute.get_replica_context().all_reduce(\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mall_reduce\u001b[1;34m(self, reduce_op, value, options)\u001b[0m\n\u001b[0;32m   3271\u001b[0m         \u001b[1;31m# The gradient of an all-sum is itself an all-sum (all-mean, likewise).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3272\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdy_s\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3273\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mflattened_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3274\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3275\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhas_indexed_slices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *a, **k)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;34m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_eager_mode_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_graph_mode_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[0m in \u001b[0;36m_eager_mode_decorator\u001b[1;34m(f, args, kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m       nest.flatten(result))\n\u001b[0;32m    564\u001b[0m   \u001b[1;31m# TODO(apassos) consider removing the identity below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m   \u001b[0mflat_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   input_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    563\u001b[0m       nest.flatten(result))\n\u001b[0;32m    564\u001b[0m   \u001b[1;31m# TODO(apassos) consider removing the identity below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m   \u001b[0mflat_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   input_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4833\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4834\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4835\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   4836\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[0;32m   4837\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# env = gym.make(\"Pendulum-v1\", g=9.81, render_mode=\"human\")\n",
    "env = gym.make(\"Pendulum-v1\", g=9.81)\n",
    "\n",
    "model = DQN(3, 9)\n",
    "\n",
    "\n",
    "for episode in range(200):\n",
    "    state, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    step = 0\n",
    "\n",
    "    rewards = []\n",
    "    before_reward = None\n",
    "\n",
    "    while not terminated and step < 300:\n",
    "\n",
    "        # 모델로 행동 예측\n",
    "        action = model.call(np.array([state])).numpy()[0]\n",
    "        action = np.random.choice(9, p=action)\n",
    "        # 행동 실행\n",
    "        next_state, reward, terminated, truncated, info = env.step((action/2-2,))\n",
    "    \n",
    "\n",
    "        # 리플레이 버퍼에 기억\n",
    "        model.remember(state, action, reward, next_state, terminated)\n",
    "        \n",
    "        # 모델 업데이트\n",
    "        update_model(model)\n",
    "\n",
    "        state = next_state\n",
    "        step += 1\n",
    "\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    print(\"Episode: {}, Steps: {}, Score: {}\".format(episode, step, sum(rewards) / len(rewards)))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a 2-dimensional array of shape (3, 4) with random floats between 0 and 1\n",
    "random_array = np.random.randint(9)\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frequency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
